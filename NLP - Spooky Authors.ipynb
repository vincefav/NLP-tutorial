{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python NLP Tutorial\n",
    "\n",
    "The dataset I'll be using is the Kaggle \"Spooky Authors\" competition -- given a writing sample, can we predict which author penned it? Our options are Edgar Allen Poe, HP Lovecraft, and Mary Shelley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (cross_val_score, GridSearchCV,\n",
    "                                     train_test_split, KFold)\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "data = data.sample(frac=1.0) # shuffle\n",
    "# Shuffling isn't ever really necessary, but it's good to be cautious!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>id22852</td>\n",
       "      <td>His careless extravagance, which made him squa...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>id00476</td>\n",
       "      <td>and was he not consequently damned?</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>id03406</td>\n",
       "      <td>To a sensitive mind there is always more or le...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>id03072</td>\n",
       "      <td>I vaow afur Gawd, I dun't know what he wants n...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>id19412</td>\n",
       "      <td>Such as he had now become, such as was his ter...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12528</th>\n",
       "      <td>id09587</td>\n",
       "      <td>Trever seemed dazed in the confusion, and shra...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14417</th>\n",
       "      <td>id21015</td>\n",
       "      <td>\"Hem ahem rather civil that, I should say\" sai...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>id15308</td>\n",
       "      <td>Wherefore should I see her?</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14289</th>\n",
       "      <td>id27422</td>\n",
       "      <td>The Greeks wept for joy when they beheld the M...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>id10438</td>\n",
       "      <td>All the time she could command she spent in so...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "15980  id22852  His careless extravagance, which made him squa...    MWS\n",
       "4722   id00476                and was he not consequently damned?    EAP\n",
       "5011   id03406  To a sensitive mind there is always more or le...    EAP\n",
       "102    id03072  I vaow afur Gawd, I dun't know what he wants n...    HPL\n",
       "6491   id19412  Such as he had now become, such as was his ter...    MWS\n",
       "12528  id09587  Trever seemed dazed in the confusion, and shra...    HPL\n",
       "14417  id21015  \"Hem ahem rather civil that, I should say\" sai...    EAP\n",
       "7717   id15308                        Wherefore should I see her?    MWS\n",
       "14289  id27422  The Greeks wept for joy when they beheld the M...    MWS\n",
       "8723   id10438  All the time she could command she spent in so...    MWS"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "Stemming is the process of reducing words down to their roots. It's commonly taught as part of NLP, but in my experience it typically doesn't help with a model's performance.\n",
    "\n",
    "In fact, it's been so long since I'm stemmed, I forget the most efficient way to code it. The example below works fine, but I remember learning it a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# There are several different stemmers,\n",
    "# but Snowball tends to do the best job.\n",
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed = []\n",
    "\n",
    "for sample in data['text']:\n",
    "    # Stem each word and then rejoin them all to a string\n",
    "    st = \" \".join([stemmer.stem(word) for word in sample.split()])\n",
    "    stemmed.append(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not going to be very conscientious about training and testing splits, since that's not really the purpose of this notebook. For teaching purposes, simple cross validation is fine IMO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array(stemmed)\n",
    "y = data['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Pipelines usually aren't necessary for ML tasks -- but when they are, they're absolutely essential. They allow you to run your data through multiple steps before your model makes a prediction.\n",
    "\n",
    "The main time I use them is for NLP tasks like this. I'll walk you through the process:\n",
    "\n",
    "```\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "```\n",
    "\n",
    "You'll then use this just like you would any other machine learning model (e.g. `LogisticRegression()`)\n",
    "\n",
    "There are at least 2 ways to create a pipeline, and this is the more difficult (but flexible) way. You pass a **list of tuples** to the Pipeline class.\n",
    "\n",
    "- The 2nd item in each tuple is a step in your machine learning model.\n",
    "\n",
    "- The 1st item is what you want to call it.\n",
    "\n",
    "\"What you want to call it?\" I know that sounds weird, but you'll see why that's useful in a moment.\n",
    "\n",
    "Let's continue on by seeing how a dummy classifier does in terms of predicting accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.34041551160391936\n",
      "Std Dev:    0.0031701578217426434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dum = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classify', DummyClassifier())\n",
    "])\n",
    "\n",
    "# Here's what I mean by treating your pipeline like any other model\n",
    "cv = cross_val_score(dum, x, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very good since each author represents about a third of the data. \n",
    "\n",
    "`MultinomialNB()` is the classifier you'll most often use for NLP. It's fast and does a great job. Other classifiers, like logistic regression or decision trees work too, but try them out and you'll see why I usually don't bother.\n",
    "\n",
    "Pay close attention to how I set up my parameter grid below. For each parameter in your pipeline, you refer to it by the name you gave the step, followed by 2 underscores, followed by the parameter you're testing. Examine the code and it'll make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.04, max_features=None, min_df=4,\n",
      "        ngram_range=(1, 2), norm='l1', preprocessor=None, smooth_idf=True,\n",
      "...        vocabulary=None)), ('classify', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))])\n",
      "Mean score: 0.4025746959129042\n",
      "Std Dev:    0.006219236493607164\n"
     ]
    }
   ],
   "source": [
    "pl = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'tfidf__max_df': np.arange(.01,.10,.01),\n",
    "        'tfidf__min_df': [2,3,4],\n",
    "        'tfidf__ngram_range': [(1,2)],\n",
    "        'tfidf__norm': ['l1', 'l2'],\n",
    "        'classify__alpha': [.01, .1, .2],\n",
    "    },\n",
    "]\n",
    "# If you're curious why I enclosed my grid dictionary in a list,\n",
    "# I actually don't remember. :) There are certain advanced use cases\n",
    "# where you might have multiple grids.\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=kf, param_grid=param_grid, scoring='accuracy')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model_nb = grid.best_estimator_\n",
    "print(model_nb)\n",
    "cv = cross_val_score(model_nb, x, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that that's our accuracy score with stemmed words. It's actually not all that good! Let's try again with our original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.03, max_features=None, min_df=4,\n",
      "        ngram_range=(1, 2), norm='l1', preprocessor=None, smooth_idf=True,\n",
      "...        vocabulary=None)), ('classify', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))])\n",
      "Mean score: 0.6775116535934644\n",
      "Std Dev:    0.002423282058608898\n"
     ]
    }
   ],
   "source": [
    "x = data['text']\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'tfidf__max_df': [.03,.04,.05],\n",
    "        'tfidf__min_df': [4],\n",
    "        'tfidf__ngram_range': [(1,2)],\n",
    "        'tfidf__norm': ['l1'],\n",
    "        'classify__alpha': [.2],\n",
    "    },\n",
    "]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=kf, param_grid=param_grid, scoring='accuracy')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model_nb = grid.best_estimator_\n",
    "print(model_nb)\n",
    "cv = cross_val_score(model_nb, x, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MUCH better, right? If you have the time and motivation, you could improve it even further, but let me show you one more trick I like to do with NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_nb.fit(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upstream', 'cord', 'blitzen', 'coffins', 'mizzen']\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "# Again, here's why you named each step in your pipeline\n",
    "# .vocabulary_ is actually a dictionary, but it contains all the\n",
    "# words your vectorizer encountered.\n",
    "tfidf_words = model_nb.named_steps['tfidf'].vocabulary_\n",
    "\n",
    "# Let's print a few random words!\n",
    "s = sample(list(tfidf_words), 5)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "# For each word in the vocabulary\n",
    "for word in tfidf_words.keys():\n",
    "    \n",
    "    # Predict the class of that word\n",
    "    # (Notice the word has to be put in a list\n",
    "    # And you'll typically have to do a bit of indexing\n",
    "    # as well -- in this case, [0])\n",
    "    pred = model_nb.predict_proba([word])[0]\n",
    "    \n",
    "    # Add that word and its predictions to our new \"scores\" dict\n",
    "    scores[word] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That `model_nb.predict_proba([word])[0]` is not at all what you'd expect, right? In a perfectly logical world, the code would shorten to `model_nb.predict_proba(word)`.\n",
    "\n",
    "I'm pointing this out as a tip to people who are still newish to Python in general. **When you're not sure what kinds of outputs and datatypes you're dealing with, debug them by printing them out.** Then look at whether you need to do additional indexing, conversion, etc.\n",
    "\n",
    "Sure, there are more advanced debugging methods out there, but the print function will solve 99% of your problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaem</th>\n",
       "      <td>[0.40349353899586293, 0.2878083661065427, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>[0.40349353899586293, 0.2878083661065427, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>[0.40349353899586293, 0.2878083661065427, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaft</th>\n",
       "      <td>[0.40349353899586293, 0.2878083661065427, 0.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>[0.5266669572934571, 0.25686285964094774, 0.21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       "aaem     [0.40349353899586293, 0.2878083661065427, 0.30...\n",
       "ab       [0.40349353899586293, 0.2878083661065427, 0.30...\n",
       "aback    [0.40349353899586293, 0.2878083661065427, 0.30...\n",
       "abaft    [0.40349353899586293, 0.2878083661065427, 0.30...\n",
       "abandon  [0.5266669572934571, 0.25686285964094774, 0.21..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I hate this syntax, but I think it's the fastest\n",
    "# way to convert a dict to a dataframe\n",
    "scores = pd.DataFrame([scores]).T\n",
    "\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! That's not useful at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hesitates</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perpetrate</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautify</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throb</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physiology</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoky</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ailments</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whispers</th>\n",
       "      <td>0.252173</td>\n",
       "      <td>0.454014</td>\n",
       "      <td>0.293813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diotima</th>\n",
       "      <td>0.330113</td>\n",
       "      <td>0.283243</td>\n",
       "      <td>0.386644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perticcler</th>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2\n",
       "hesitates   0.403494  0.287808  0.308698\n",
       "perpetrate  0.403494  0.287808  0.308698\n",
       "beautify    0.403494  0.287808  0.308698\n",
       "throb       0.403494  0.287808  0.308698\n",
       "physiology  0.403494  0.287808  0.308698\n",
       "smoky       0.403494  0.287808  0.308698\n",
       "ailments    0.403494  0.287808  0.308698\n",
       "whispers    0.252173  0.454014  0.293813\n",
       "diotima     0.330113  0.283243  0.386644\n",
       "perticcler  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This converts a column of lists into multiple columns\n",
    "# in effect \"expanding\" it\n",
    "# Again, really weird syntax but super useful\n",
    "\n",
    "scores = scores[0].apply(pd.Series)\n",
    "\n",
    "scores.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I had to look up the order and figure it out manually\n",
    "# I'm sure there's a better way!\n",
    "\n",
    "scores.columns = ['Poe', 'Lovecraft', 'Shelley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poe</th>\n",
       "      <th>Lovecraft</th>\n",
       "      <th>Shelley</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dupin</th>\n",
       "      <td>0.914451</td>\n",
       "      <td>0.041665</td>\n",
       "      <td>0.043884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marie</th>\n",
       "      <td>0.883941</td>\n",
       "      <td>0.056525</td>\n",
       "      <td>0.059534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>madame</th>\n",
       "      <td>0.879644</td>\n",
       "      <td>0.042088</td>\n",
       "      <td>0.078267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jupiter</th>\n",
       "      <td>0.878962</td>\n",
       "      <td>0.058950</td>\n",
       "      <td>0.062088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balloon</th>\n",
       "      <td>0.876592</td>\n",
       "      <td>0.054143</td>\n",
       "      <td>0.069265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automaton</th>\n",
       "      <td>0.860367</td>\n",
       "      <td>0.061508</td>\n",
       "      <td>0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diddle</th>\n",
       "      <td>0.857114</td>\n",
       "      <td>0.069590</td>\n",
       "      <td>0.073296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monsieur</th>\n",
       "      <td>0.856356</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diddler</th>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.069968</td>\n",
       "      <td>0.073694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chess</th>\n",
       "      <td>0.845633</td>\n",
       "      <td>0.079950</td>\n",
       "      <td>0.074417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Poe  Lovecraft   Shelley\n",
       "dupin      0.914451   0.041665  0.043884\n",
       "marie      0.883941   0.056525  0.059534\n",
       "madame     0.879644   0.042088  0.078267\n",
       "jupiter    0.878962   0.058950  0.062088\n",
       "balloon    0.876592   0.054143  0.069265\n",
       "automaton  0.860367   0.061508  0.078125\n",
       "diddle     0.857114   0.069590  0.073296\n",
       "monsieur   0.856356   0.069959  0.073684\n",
       "diddler    0.856338   0.069968  0.073694\n",
       "chess      0.845633   0.079950  0.074417"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poe words\n",
    "scores.sort_values('Poe', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poe</th>\n",
       "      <th>Lovecraft</th>\n",
       "      <th>Shelley</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gilman</th>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.890681</td>\n",
       "      <td>0.050447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>innsmouth</th>\n",
       "      <td>0.067213</td>\n",
       "      <td>0.875192</td>\n",
       "      <td>0.057595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arkham</th>\n",
       "      <td>0.075709</td>\n",
       "      <td>0.859416</td>\n",
       "      <td>0.064875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whateley</th>\n",
       "      <td>0.085385</td>\n",
       "      <td>0.841449</td>\n",
       "      <td>0.073166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>later</th>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.822405</td>\n",
       "      <td>0.049571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jermyn</th>\n",
       "      <td>0.111046</td>\n",
       "      <td>0.812859</td>\n",
       "      <td>0.076095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armitage</th>\n",
       "      <td>0.101960</td>\n",
       "      <td>0.810672</td>\n",
       "      <td>0.087368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>despite</th>\n",
       "      <td>0.099299</td>\n",
       "      <td>0.809283</td>\n",
       "      <td>0.091418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folk</th>\n",
       "      <td>0.106462</td>\n",
       "      <td>0.802311</td>\n",
       "      <td>0.091227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aout</th>\n",
       "      <td>0.107131</td>\n",
       "      <td>0.801068</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Poe  Lovecraft   Shelley\n",
       "gilman     0.058872   0.890681  0.050447\n",
       "innsmouth  0.067213   0.875192  0.057595\n",
       "arkham     0.075709   0.859416  0.064875\n",
       "whateley   0.085385   0.841449  0.073166\n",
       "later      0.128023   0.822405  0.049571\n",
       "jermyn     0.111046   0.812859  0.076095\n",
       "armitage   0.101960   0.810672  0.087368\n",
       "despite    0.099299   0.809283  0.091418\n",
       "folk       0.106462   0.802311  0.091227\n",
       "aout       0.107131   0.801068  0.091800"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lovecraft words\n",
    "scores.sort_values('Lovecraft', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poe</th>\n",
       "      <th>Lovecraft</th>\n",
       "      <th>Shelley</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raymond</th>\n",
       "      <td>0.019843</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.957340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perdita</th>\n",
       "      <td>0.027295</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.950498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adrian</th>\n",
       "      <td>0.032765</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>0.940578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idris</th>\n",
       "      <td>0.042039</td>\n",
       "      <td>0.034202</td>\n",
       "      <td>0.923758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windsor</th>\n",
       "      <td>0.056153</td>\n",
       "      <td>0.045685</td>\n",
       "      <td>0.898162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elizabeth</th>\n",
       "      <td>0.054179</td>\n",
       "      <td>0.052539</td>\n",
       "      <td>0.893282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misery</th>\n",
       "      <td>0.086720</td>\n",
       "      <td>0.039718</td>\n",
       "      <td>0.873562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sister</th>\n",
       "      <td>0.074425</td>\n",
       "      <td>0.058940</td>\n",
       "      <td>0.866635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justine</th>\n",
       "      <td>0.075260</td>\n",
       "      <td>0.061230</td>\n",
       "      <td>0.863510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miserable</th>\n",
       "      <td>0.099440</td>\n",
       "      <td>0.043885</td>\n",
       "      <td>0.856676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Poe  Lovecraft   Shelley\n",
       "raymond    0.019843   0.022816  0.957340\n",
       "perdita    0.027295   0.022207  0.950498\n",
       "adrian     0.032765   0.026657  0.940578\n",
       "idris      0.042039   0.034202  0.923758\n",
       "windsor    0.056153   0.045685  0.898162\n",
       "elizabeth  0.054179   0.052539  0.893282\n",
       "misery     0.086720   0.039718  0.873562\n",
       "sister     0.074425   0.058940  0.866635\n",
       "justine    0.075260   0.061230  0.863510\n",
       "miserable  0.099440   0.043885  0.856676"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shelley words\n",
    "scores.sort_values('Shelley', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
